# ğŸ“‰ ANN-Based Customer Churn Prediction

This project builds an **Artificial Neural Network (ANN)** model to predict whether a customer will churn (leave a service) or not, using a real-world bank customer dataset. It demonstrates how deep learning models can be used to handle classification problems in customer retention and engagement.

---

## ğŸ“Œ About the Project

Customer churn is a critical business metric that can help companies retain valuable users. This project uses an ANN built with **TensorFlow and Keras** to classify customers based on their likelihood of churning.

The model was trained on various features such as credit score, geography, tenure, balance, and activity. After preprocessing and model training, it achieved high accuracy in predicting churn behavior.

---

## ğŸ§° Tech Stack

- **Language:** Python  
- **Libraries:** TensorFlow, Keras, Pandas, NumPy, Scikit-learn, Matplotlib  
- **Model:** Artificial Neural Network (Sequential model)  
- **Data Source:** Bank Customer Churn Dataset

---

## ğŸ“Š Features Used

- Credit Score  
- Geography  
- Gender  
- Age  
- Tenure  
- Balance  
- Number of Products  
- Has Credit Card  
- Is Active Member  
- Estimated Salary

---

## ğŸš€ How to Run

```bash
# Clone the repository
git clone https://github.com/shivam-kr935/ANN_Customer_Churn_Prediction.git
cd ANN_Customer_Churn_Prediction

# Install dependencies
pip install -r requirements.txt

# Run the main script (example)
python ann_churn_model.py

ğŸ“‹ Model Performance
Metric	Value (approx.)
Accuracy	86%
Precision	High
Recall	Balanced

Performance may vary based on random seed, tuning, and train-test split.

ğŸ“ Project Structure
bash
Copy
Edit
.
â”œâ”€â”€ ann_churn_model.py        # ANN training & evaluation
â”œâ”€â”€ churn_prediction_model.h5 # Saved model
â”œâ”€â”€ dataset/                  # Contains Churn_Modelling.csv
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ§  Model Architecture
Hereâ€™s a breakdown of the ANN model used:

Input Layer:
11 features after encoding categorical variables.

Hidden Layer 1:
6 neurons, activation = ReLU

Hidden Layer 2:
6 neurons, activation = ReLU

Output Layer:
1 neuron, activation = Sigmoid (for binary classification)

Loss Function:
Binary Crossentropy

Optimizer:
Adam

Metric:
Accuracy

ğŸ‘¤ Author
Shivam Kumar
ğŸ”— LinkedIn
ğŸ’» GitHub
